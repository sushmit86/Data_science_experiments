{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import random, math\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import manifold\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Plot2DBoundary(DTrain, LTrain, DTest, LTest):\n",
    "  # The dots are training samples (img not drawn), and the pics are testing samples (images drawn)\n",
    "  # Play around with the K values. This is very controlled dataset so it should be able to get perfect classification on testing entries\n",
    "  # Play with the K for isomap, play with the K for neighbors. \n",
    "\n",
    "  fig = plt.figure()\n",
    "  ax = fig.add_subplot(111)\n",
    "  ax.set_title('Transformed Boundary, Image Space -> 2D')\n",
    "\n",
    "  padding = 0.1   # Zoom out\n",
    "  resolution = 1  # Don't get too detailed; smaller values (finer rez) will take longer to compute\n",
    "  colors = ['blue','green','orange','red']\n",
    "  \n",
    "\n",
    "  # ------\n",
    "\n",
    "  # Calculate the boundaries of the mesh grid. The mesh grid is\n",
    "  # a standard grid (think graph paper), where each point will be\n",
    "  # sent to the classifier (KNeighbors) to predict what class it\n",
    "  # belongs to. This is why KNeighbors has to be trained against\n",
    "  # 2D data, so we can produce this countour. Once we have the \n",
    "  # label for each point on the grid, we can color it appropriately\n",
    "  # and plot it.\n",
    "  x_min, x_max = DTrain[:, 0].min(), DTrain[:, 0].max()\n",
    "  y_min, y_max = DTrain[:, 1].min(), DTrain[:, 1].max()\n",
    "  x_range = x_max - x_min\n",
    "  y_range = y_max - y_min\n",
    "  x_min -= x_range * padding\n",
    "  y_min -= y_range * padding\n",
    "  x_max += x_range * padding\n",
    "  y_max += y_range * padding\n",
    "\n",
    "  # Using the boundaries, actually make the 2D Grid Matrix:\n",
    "  xx, yy = np.meshgrid(np.arange(x_min, x_max, resolution),\n",
    "                       np.arange(y_min, y_max, resolution))\n",
    "\n",
    "  # What class does the classifier say about each spot on the chart?\n",
    "  # The values stored in the matrix are the predictions of the model\n",
    "  # at said location:\n",
    "  Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "  Z = Z.reshape(xx.shape)\n",
    "\n",
    "  # Plot the mesh grid as a filled contour plot:\n",
    "  plt.contourf(xx, yy, Z, cmap=plt.cm.terrain, z=-100)\n",
    "\n",
    "\n",
    "  # ------\n",
    "\n",
    "  # When plotting the testing images, used to validate if the algorithm\n",
    "  # is functioning correctly, size them as 5% of the overall chart size\n",
    "  x_size = x_range * 0.05\n",
    "  y_size = y_range * 0.05\n",
    "  \n",
    "  # First, plot the images in your TEST dataset\n",
    "  img_num = 0\n",
    "  for index in LTest.index:\n",
    "    # DTest is a regular NDArray, so you'll iterate over that 1 at a time.\n",
    "    x0, y0 = DTest[img_num,0]-x_size/2., DTest[img_num,1]-y_size/2.\n",
    "    x1, y1 = DTest[img_num,0]+x_size/2., DTest[img_num,1]+y_size/2.\n",
    "\n",
    "    # DTest = our images isomap-transformed into 2D. But we still want\n",
    "    # to plot the original image, so we look to the original, untouched\n",
    "    # dataset (at index) to get the pixels:\n",
    "    img = df.iloc[index,:].reshape(num_pixels, num_pixels)\n",
    "    ax.imshow(img, aspect='auto', cmap=plt.cm.gray, interpolation='nearest', zorder=100000, extent=(x0, x1, y0, y1), alpha=0.8)\n",
    "    img_num += 1\n",
    "\n",
    "\n",
    "  # Plot your TRAINING points as well... as points rather than as images\n",
    "  for label in range(len(np.unique(LTrain))):\n",
    "    indices = np.where(LTrain == label)\n",
    "    ax.scatter(DTrain[indices, 0], DTrain[indices, 1], c=colors[label], alpha=0.8, marker='o')\n",
    "\n",
    "  # Plot\n",
    "  plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# TODO: Use the same code from Module4/assignment4.py to load up the\n",
    "# face_data.mat in a dataset called \"df\". Be sure to calculate the\n",
    "# num_pixels value, and to rotate the images to being right-side-up\n",
    "# instead of sideways. This was demonstrated in the M4/A4 code:\n",
    "#\n",
    "# .. your code here ..\n",
    "# A .MAT file is a .MATLAB file. The faces dataset could have came\n",
    "# in through .png images, but we'll show you how to do that in\n",
    "# another lab. For now, you'll see how to import .mats:\n",
    "mat = scipy.io.loadmat('/Users/sroy/Personal/Data_science_experiments/DAT210x_sushmit/Module4/Datasets/face_data.mat')\n",
    "df = pd.DataFrame(mat['images']).T\n",
    "num_images, num_pixels = df.shape\n",
    "num_pixels = int(math.sqrt(num_pixels))\n",
    "\n",
    "# Rotate the pictures, so we don't have to crane our necks:\n",
    "for i in range(num_images):\n",
    "  df.loc[i,:] = df.loc[i,:].reshape(num_pixels, num_pixels).T.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# TODO: Load up your face_labels dataset. It only has a single column, and\n",
    "# you're only interested in that single column. You will have to slice the \n",
    "# column out so that you have access to it as a \"Series\" rather than as a\n",
    "# \"Dataframe\". Use an appropriate indexer to take care of that. Also print\n",
    "# out the labels and compare to the face_labels.csv file to ensure you\n",
    "# loaded it correctly\n",
    "#\n",
    "# .. your code here ..\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "# TODO: Do train_test_split. Use the same code as on the EdX platform in the\n",
    "# reading material, but set the random_state=7 for reproduceability, and play\n",
    "# around with the test_size from 0.10 - 0.20 (10-20%). Your labels are actually\n",
    "# passed in as a series (instead of as an NDArray) so that you can access\n",
    "# their underlying indices later on. This is necessary so you can find your samples\n",
    "# in the original dataframe, which you will use to plot your testing data as images\n",
    "# rather than as points:\n",
    "#\n",
    "# .. your code here .."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
