{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import PCA,KernelPCA\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practise data set\n",
    "We will be using the numerai data set for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Loading data...\n"
     ]
    }
   ],
   "source": [
    "print(\"# Loading data...\")\n",
    "# The training data is used to train your model how to predict the targets.\n",
    "train = pd.read_csv('numerai_datasets/numerai_training_data.csv', header=0)\n",
    "# The tournament data is the data that Numerai uses to evaluate your model.\n",
    "tournament = pd.read_csv('numerai_datasets/numerai_tournament_data.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The tournament data contains validation data, test data and live data.\n",
    "# Validation is used to test your model locally so we separate that.\n",
    "validation = tournament[tournament['data_type']=='validation']\n",
    "test = tournament[tournament['data_type']=='test']\n",
    "live = tournament[tournament['data_type']=='live']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(393613, 58)\n",
      "(243037, 58)\n",
      "(4070, 58)\n",
      "(192605, 58)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(tournament.shape)\n",
    "print(live.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bernie = train.drop([\n",
    "    'id', 'era', 'data_type',\n",
    "    'target_charles', 'target_elizabeth',\n",
    "    'target_jordan', 'target_ken'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit Pipeline method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.516\n",
      "Log loss : 0.692\n"
     ]
    }
   ],
   "source": [
    "# Transform the loaded CSV data into numpy arrays\n",
    "features = [f for f in list(train_bernie) if \"feature\" in f]\n",
    "X_train = train_bernie[features]\n",
    "y_train = train_bernie['target_bernie']\n",
    "sc = StandardScaler()\n",
    "X_train_std = sc.fit_transform(X_train)\n",
    "pca = PCA()\n",
    "X_train_pca = pca.fit_transform(X_train_std)\n",
    "pca_n_dim=pca.explained_variance_ratio_.cumsum()\n",
    "n_dim=np.argwhere(pca_n_dim>0.9)[0]\n",
    "X_train = train_bernie[features]\n",
    "y_train = train_bernie['target_bernie']\n",
    "pipe_lr = make_pipeline(StandardScaler(),PCA(n_components=n_dim[0]),LogisticRegression(random_state=1,penalty='l1',C=0.01))\n",
    "#pipe_lr = make_pipeline(StandardScaler(),PCA(n_components=5),SVC(kernel='rbf', random_state=1, gamma=0.10, C=10.0))\n",
    "pipe_lr.fit(X_train, y_train)\n",
    "validation_bernie = validation.drop([\n",
    "    'id', 'era', 'data_type',\n",
    "    'target_charles', 'target_elizabeth',\n",
    "    'target_jordan', 'target_ken'], axis=1)\n",
    "# Transform the loaded CSV data into numpy arrays\n",
    "features = [f for f in list(validation_bernie) if \"feature\" in f]\n",
    "X_test = validation_bernie[features]\n",
    "y_test = validation_bernie['target_bernie']\n",
    "\n",
    "y_pred = pipe_lr.predict(X_test)\n",
    "print('Test Accuracy: %.3f' % pipe_lr.score(X_test, y_test))\n",
    "print('Log loss : %.3f' % log_loss(y_test,pipe_lr.predict_proba(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:  1, Class dist.: [177153 177098], Acc: 0.517\n",
      "Fold:  2, Class dist.: [177153 177098], Acc: 0.516\n",
      "Fold:  3, Class dist.: [177153 177098], Acc: 0.513\n",
      "Fold:  4, Class dist.: [177153 177098], Acc: 0.515\n",
      "Fold:  5, Class dist.: [177153 177098], Acc: 0.498\n",
      "Fold:  6, Class dist.: [177153 177098], Acc: 0.504\n",
      "Fold:  7, Class dist.: [177153 177099], Acc: 0.517\n",
      "Fold:  8, Class dist.: [177154 177099], Acc: 0.516\n",
      "Fold:  9, Class dist.: [177154 177099], Acc: 0.507\n",
      "Fold: 10, Class dist.: [177154 177099], Acc: 0.512\n",
      "\n",
      "CV accuracy: 0.511 +/- 0.006\n"
     ]
    }
   ],
   "source": [
    "X_train = train_bernie[features].values\n",
    "y_train = train_bernie['target_bernie'].values\n",
    "kfold = StratifiedKFold(n_splits=10,random_state=1).split(X_train,y_train)\n",
    "pipe_lr = make_pipeline(StandardScaler(),PCA(n_components=n_dim[0]),LogisticRegression(random_state=1))\n",
    "scores = []\n",
    "for k, (train, test) in enumerate(kfold):\n",
    "    pipe_lr.fit(X_train[train], y_train[train])\n",
    "    score = pipe_lr.score(X_train[test], y_train[test])\n",
    "    scores.append(score)\n",
    "    print('Fold: %2d, Class dist.: %s, Acc: %.3f' % (k+1,\n",
    "          np.bincount(y_train[train]), score))\n",
    "    \n",
    "print('\\nCV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing no of jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy scores: [0.51730095 0.51595447 0.51277882 0.51524313 0.49794218 0.50353132\n",
      " 0.51650111 0.51575203 0.50708841 0.51163618]\n",
      "CV accuracy: 0.511 +/- 0.006\n",
      "35.7 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(estimator=pipe_lr,\n",
    "                         X=X_train,\n",
    "                         y=y_train,\n",
    "                         cv=10,\n",
    "                         n_jobs=1)\n",
    "print('CV accuracy scores: %s' % scores)\n",
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy scores: [0.51730095 0.51595447 0.51280423 0.51531934 0.49791677 0.50348051\n",
      " 0.51650111 0.51585366 0.50706301 0.51163618]\n",
      "CV accuracy: 0.511 +/- 0.006\n",
      "20.6 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(estimator=pipe_lr,\n",
    "                         X=X_train,\n",
    "                         y=y_train,\n",
    "                         cv=10,\n",
    "                         n_jobs=-1)\n",
    "print('CV accuracy scores: %s' % scores)\n",
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
